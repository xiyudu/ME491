{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 16: Clustering and Classification\n",
        "\n",
        "We will start discussing Ch. 5 of the textbook today.  Topics we will cover from Ch.5 are:\n",
        "* 5.1 Feature Selection and Data Mining\n",
        "* 5.2 Supervised vs. Unsupervised Learning\n",
        "* 5.3 $k$-means clustering\n",
        "* 5.6 Supervised Learning and Linear Discriminants\n",
        "* 5.7 Support Vector Machines (SVM)\n",
        "\n",
        "Today, we will explore how to reduce high-dimenional data to lower-dimensions (ranks) and explain how to conduct feature selection to build models."
      ],
      "metadata": {
        "id": "2hmJa_P0sYEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ey5O5XTJAiVX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.rcParams['xtick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['ytick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['axes.linewidth']=1        # change the line width of the axis\n",
        "plt.rcParams['xtick.major.width'] = 3   # change the tick line width of x axis\n",
        "plt.rcParams['ytick.major.width'] = 3   # change the tick line width of y axis\n",
        "rc('text', usetex=False)                # disable LaTeX rendering in plots\n",
        "rc('font',**{'family':'DejaVu Sans'})   # set the font of the plot to be DejaVu Sans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVTCBQ3pZ8fV",
        "outputId": "a86d7e11-45a6-4ada-b91a-2616f82c0dfc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Feature Selection and Data Mining\n",
        "\n",
        "#### Dataset 1: Fisher iris data set\n",
        "Fisher iris data set with 150 measurements over three varieties, in- cluding 50 measurements each of Iris setosa, I. versicolor, and I. virginica. Each flower includes a measurement of sepal length, sepal width, petal length, and petal width."
      ],
      "metadata": {
        "id": "tlut0nzAtEnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/ME491\"\n",
        "data1_path = os.path.join(path, \"data/fisheriris.mat\")"
      ],
      "metadata": {
        "id": "XLTnIhGFs9n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import io\n",
        "\n",
        "fisheriris_mat = io.loadmat(data1_path)\n",
        "meas = fisheriris_mat['meas']\n",
        "species = fisheriris_mat['species']"
      ],
      "metadata": {
        "id": "lcArlmetuFBl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Exercise 1**\n",
        "\n",
        "Look at the two variables `meas` and `species`, and try to understand what do them mean, and how can you visualize it."
      ],
      "metadata": {
        "id": "ATfUkLTebWWn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtQ4NENHD4DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fisher iris dataset is easy to visualize and understand, as there are four distinct features determined *a priori* based on biological understanding for the flowers. In this case, the features are already selected and we do not need to do much.\n",
        "\n",
        "Now we turn to a dataset where we need to use what we learned in Ch.1 to identify features.\n",
        "\n",
        "#### Dataset 2: dogs and cats\n",
        "an image database of 80 dogs and 80 cats\n",
        "\n",
        "The data for each cat and dog is the $64\\times64$ pixel space of the image. Thus each image has $4096$ measurements, in contrast to the four measurements for each example in the iris data set.\n",
        "\n",
        "The end goal is to select a finite set of features that can help us distinguish between a dog and a cat image.\n",
        "\n",
        "(Side note: if you want a laugh, image search \"dog or blueberry muffin\")"
      ],
      "metadata": {
        "id": "c-cf2E9kaL_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dog_path = os.path.join(path, \"data/dogData.mat\")\n",
        "cat_path = os.path.join(path, \"data/catData.mat\")\n",
        "dogdata_mat = io.loadmat(dog_path)\n",
        "catdata_mat = io.loadmat(cat_path)"
      ],
      "metadata": {
        "id": "Ms3aLOG0Kodd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog = dogdata_mat['dog']\n",
        "cat = catdata_mat['cat']"
      ],
      "metadata": {
        "id": "j2e8YWrte-uH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Exercise 2**\n",
        "\n",
        "Adapt the code when we drew people's faces, and draw the first 36 dogs and first 36 cats in two different cells\n",
        "\n",
        "```\n",
        "# Now we want to plot the first image of the first 36 person\n",
        "allPersons = np.zeros((n*6,m*6))\n",
        "count = 0\n",
        "\n",
        "for j in range(6):\n",
        "  for k in range(6):\n",
        "    allPersons[j*n:(j+1)*n, k*m:(k+1)*m] = np.reshape(faces[:,np.sum(nfaces[:count])],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(allPersons)\n",
        "img.set_cmap('gray')\n",
        "plt.axis('off')\n",
        "```"
      ],
      "metadata": {
        "id": "1WM7kG6qffYv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBWBvcOmD7p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature detection\n",
        "\n",
        "Now we have a general understanding of the data, we want to extract features for the dataset, and we will use PCA, similar to eigenfaces to find the dominant features."
      ],
      "metadata": {
        "id": "g1A24tZJhNlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to use the same set of coordinates to\n",
        "# describe both dogs and cats\n",
        "DC = np.concatenate((dog, cat), axis = 1)\n",
        "\n",
        "# PCA\n",
        "avgAnimal = np.mean(DC, axis = 1)\n",
        "X = DC - np.tile(avgAnimal, (DC.shape[1], 1)).T\n",
        "U, S, VT = np.linalg.svd(X, full_matrices = False)"
      ],
      "metadata": {
        "id": "9echrujAgK_4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the average animal\n",
        "plt.imshow(np.reshape(avgAnimal, (m,n)).T, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "YOc9yNx1ivov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Let's plot the first 10 animal features\n",
        "\n",
        "i = 2\n",
        "j = 5\n",
        "\n",
        "eigenanimal = np.zeros((n*i, m*j))\n",
        "count = 0\n",
        "\n",
        "for ii in range(i):\n",
        "  for jj in range(j):\n",
        "    eigenanimal[ii*n:(ii+1)*n, jj*m:(jj+1)*m] = np.reshape(U[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(eigenanimal, vmin = -1e-2, vmax = 1e-2, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "8ySN266ujCz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog_w_path = os.path.join(path, \"data/dogData_w.mat\")\n",
        "cat_w_path = os.path.join(path, \"data/catData_w.mat\")\n",
        "dogwdata_mat = io.loadmat(dog_w_path)\n",
        "catwdata_mat = io.loadmat(cat_w_path)\n",
        "dog_w = dogwdata_mat['dog_wave']\n",
        "cat_w = catwdata_mat['cat_wave']"
      ],
      "metadata": {
        "id": "8RbxuuFHjg-4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we want to plot the first 36 dogs\n",
        "n = 32\n",
        "m = 32\n",
        "alldogs_w = np.zeros((n*6,m*6))\n",
        "count = 0\n",
        "\n",
        "for j in range(6):\n",
        "  for k in range(6):\n",
        "    alldogs_w[j*n:(j+1)*n, k*m:(k+1)*m] = np.reshape(dog_w[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(alldogs_w)\n",
        "img.set_cmap('gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "5Q2F9v_Mj7dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DC_w = np.concatenate((dog_w, cat_w), axis = 1)\n",
        "\n",
        "# PCA\n",
        "avgAnimal_w = np.mean(DC_w, axis = 1)\n",
        "Xw = DC_w - np.tile(avgAnimal_w, (DC_w.shape[1],1)).T\n",
        "Uw, Sw, VTw = np.linalg.svd(Xw, full_matrices = False)"
      ],
      "metadata": {
        "id": "3TugFcl2kImP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the average animal\n",
        "plt.imshow(np.reshape(avgAnimal_w, (m,n)).T, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "oubiRzPekq_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Let's plot the first 10 animal features\n",
        "\n",
        "i = 2\n",
        "j = 5\n",
        "\n",
        "eigenanimal_w = np.zeros((n*i, m*j))\n",
        "count = 0\n",
        "\n",
        "for ii in range(i):\n",
        "  for jj in range(j):\n",
        "    eigenanimal_w[ii*n:(ii+1)*n, jj*m:(jj+1)*m] = np.reshape(Uw[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(eigenanimal_w, vmin = -1e-2, vmax = 1e-2, cmap=\"coolwarm\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "GCLqJgVUkt8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we were discussing PCA in Ch. 1, we never spent too much time discussing the meaning of the $V$ matrix.  Here, we will use $V$ matrix to perform feature engineering.\n",
        "\n",
        "The importance of each feature to an individual image is given by the $V$ matrix in the SVD. Specifically, each column of $V$ determines the loading, or weighting, of each feature onto a specific image.\n",
        "\n",
        "We can now look at the distributions for the $V$ matrix for dogs and cats."
      ],
      "metadata": {
        "id": "XsG0Xw2i9Fg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xbin = np.linspace(-0.25, 0.25, 20)\n",
        "xbin_edges = np.append(xbin, xbin[-1]+(xbin[1]-xbin[0])) - (xbin[1]-xbin[0])/2\n",
        "\n",
        "fig, axs = plt.subplots(4,2)\n",
        "fig.tight_layout(h_pad=0, w_pad=2)\n",
        "fig.set_size_inches(6, 8)\n",
        "for j in range(4):\n",
        "  pdf1 = np.histogram(VT[j,:80], bins=xbin_edges)[0]\n",
        "  pdf2 = np.histogram(VT[j,80:], bins=xbin_edges)[0]\n",
        "  axs[j,0].plot(xbin, pdf1, label = \"dogs\")\n",
        "  axs[j,0].plot(xbin, pdf2, label = \"cats\")\n",
        "  axs[j,0].legend()\n",
        "  axs[j,0].set_ylabel('PCA'+str(j+1), fontsize = 18)\n",
        "\n",
        "  pdf1 = np.histogram(VTw[j,:80], bins=xbin_edges)[0]\n",
        "  pdf2 = np.histogram(VTw[j,80:], bins=xbin_edges)[0]\n",
        "  axs[j,1].plot(xbin, pdf1, label = \"dogs\")\n",
        "  axs[j,1].plot(xbin, pdf2, label = \"cats\")\n",
        "  axs[j,1].legend()\n",
        "\n",
        "axs[0,0].set_title(\"image space\", fontsize = 18)\n",
        "axs[0,1].set_title(\"wavelet space\", fontsize = 18)"
      ],
      "metadata": {
        "id": "5WgTvzKdk1Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All dog and cat images projecting to the first three PCA coordinates."
      ],
      "metadata": {
        "id": "EUYjf29Y_vO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(211, projection='3d')\n",
        "ax1.scatter(VT[0,:80],VT[1,:80],VT[2,:80],c='r',marker='o',s=20)\n",
        "ax1.scatter(VT[0,80:],VT[1,80:],VT[2,80:],c='b',marker='o',s=20)\n",
        "\n",
        "ax2 = fig.add_subplot(212, projection='3d')\n",
        "ax2.scatter(VTw[0,:80],VTw[1,:80],VTw[2,:80],c='r',marker='o',s=20)\n",
        "ax2.scatter(VTw[0,80:],VTw[1,80:],VTw[2,80:],c='b',marker='o',s=20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ypSNZWSc93-Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}