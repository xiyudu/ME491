{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 17: Feature Selection, $k$-means clustering"
      ],
      "metadata": {
        "id": "J4HkskQehRdM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nPpaQ_E5hL2-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.rcParams['xtick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['ytick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['axes.linewidth']=1        # change the line width of the axis\n",
        "plt.rcParams['xtick.major.width'] = 3   # change the tick line width of x axis\n",
        "plt.rcParams['ytick.major.width'] = 3   # change the tick line width of y axis\n",
        "rc('text', usetex=False)                # disable LaTeX rendering in plots\n",
        "rc('font',**{'family':'DejaVu Sans'})   # set the font of the plot to be DejaVu Sans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import io"
      ],
      "metadata": {
        "id": "sx6rSYF0j0Hw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOXA48J3hbBE",
        "outputId": "529aa160-a108-47f5-f517-07a794c1563a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Feature Selection and Data Mining\n",
        "\n",
        "#### Dataset 2: dogs and cats\n",
        "an image database of 80 dogs and 80 cats\n",
        "\n",
        "The data for each cat and dog is the $64\\times64$ pixel space of the image. Thus each image has $4096$ measurements, in contrast to the four measurements for each example in the iris data set.\n",
        "\n",
        "The end goal is to select a finite set of features that can help us distinguish between a dog and a cat image."
      ],
      "metadata": {
        "id": "QSgYekHlhgU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/ME491\"\n",
        "data1_path = os.path.join(path, \"data/fisheriris.mat\")\n",
        "\n",
        "dog_path = os.path.join(path, \"data/dogData.mat\")\n",
        "cat_path = os.path.join(path, \"data/catData.mat\")\n",
        "dogdata_mat = io.loadmat(dog_path)\n",
        "catdata_mat = io.loadmat(cat_path)\n",
        "dog = dogdata_mat['dog']\n",
        "cat = catdata_mat['cat']\n",
        "\n",
        "m = 64\n",
        "n = 64"
      ],
      "metadata": {
        "id": "vBbiEkKVjpDE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature detection\n",
        "\n",
        "Now we have a general understanding of the data, we want to extract features for the dataset, and we will use PCA, similar to eigenfaces to find the dominant features."
      ],
      "metadata": {
        "id": "g1A24tZJhNlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to use the same set of coordinates to\n",
        "# describe both dogs and cats\n",
        "DC = np.concatenate((dog, cat), axis = 1)\n",
        "\n",
        "# PCA\n",
        "avgAnimal = np.mean(DC, axis = 1)\n",
        "X = DC - np.tile(avgAnimal, (DC.shape[1], 1)).T\n",
        "U, S, VT = np.linalg.svd(X, full_matrices = False)"
      ],
      "metadata": {
        "id": "9echrujAgK_4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the average animal\n",
        "plt.imshow(np.reshape(avgAnimal, (m,n)).T, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "YOc9yNx1ivov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Let's plot the first 10 animal features\n",
        "\n",
        "i = 2\n",
        "j = 5\n",
        "\n",
        "eigenanimal = np.zeros((n*i, m*j))\n",
        "count = 0\n",
        "\n",
        "for ii in range(i):\n",
        "  for jj in range(j):\n",
        "    eigenanimal[ii*n:(ii+1)*n, jj*m:(jj+1)*m] = np.reshape(U[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(eigenanimal, vmin = -1e-2, vmax = 1e-2, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "8ySN266ujCz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog_w_path = os.path.join(path, \"data/dogData_w.mat\")\n",
        "cat_w_path = os.path.join(path, \"data/catData_w.mat\")\n",
        "dogwdata_mat = io.loadmat(dog_w_path)\n",
        "catwdata_mat = io.loadmat(cat_w_path)\n",
        "dog_w = dogwdata_mat['dog_wave']\n",
        "cat_w = catwdata_mat['cat_wave']"
      ],
      "metadata": {
        "id": "8RbxuuFHjg-4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we want to plot the first 36 dogs\n",
        "n = 32\n",
        "m = 32\n",
        "alldogs_w = np.zeros((n*6,m*6))\n",
        "count = 0\n",
        "\n",
        "for j in range(6):\n",
        "  for k in range(6):\n",
        "    alldogs_w[j*n:(j+1)*n, k*m:(k+1)*m] = np.reshape(dog_w[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(alldogs_w)\n",
        "img.set_cmap('gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "5Q2F9v_Mj7dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DC_w = np.concatenate((dog_w, cat_w), axis = 1)\n",
        "\n",
        "# PCA\n",
        "avgAnimal_w = np.mean(DC_w, axis = 1)\n",
        "Xw = DC_w - np.tile(avgAnimal_w, (DC_w.shape[1],1)).T\n",
        "Uw, Sw, VTw = np.linalg.svd(Xw, full_matrices = False)"
      ],
      "metadata": {
        "id": "3TugFcl2kImP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the average animal\n",
        "plt.imshow(np.reshape(avgAnimal_w, (m,n)).T, cmap=\"Greys_r\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "oubiRzPekq_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Let's plot the first 10 animal features\n",
        "\n",
        "i = 2\n",
        "j = 5\n",
        "\n",
        "eigenanimal_w = np.zeros((n*i, m*j))\n",
        "count = 0\n",
        "\n",
        "for ii in range(i):\n",
        "  for jj in range(j):\n",
        "    eigenanimal_w[ii*n:(ii+1)*n, jj*m:(jj+1)*m] = np.reshape(Uw[:,count],(m,n)).T\n",
        "    count += 1\n",
        "\n",
        "img = plt.imshow(eigenanimal_w, vmin = -1e-2, vmax = 1e-2, cmap=\"coolwarm\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "GCLqJgVUkt8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we were discussing PCA in Ch. 1, we never spent too much time discussing the meaning of the $V$ matrix.  Here, we will use $V$ matrix to perform feature engineering.\n",
        "\n",
        "The importance of each feature to an individual image is given by the $V$ matrix in the SVD. Specifically, each column of $V$ determines the loading, or weighting, of each feature onto a specific image.\n",
        "\n",
        "We can now look at the distributions for the $V$ matrix for dogs and cats."
      ],
      "metadata": {
        "id": "XsG0Xw2i9Fg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xbin = np.linspace(-0.25, 0.25, 20)\n",
        "xbin_edges = np.append(xbin, xbin[-1]+(xbin[1]-xbin[0])) - (xbin[1]-xbin[0])/2\n",
        "\n",
        "fig, axs = plt.subplots(4,2)\n",
        "fig.tight_layout(h_pad=0, w_pad=2)\n",
        "fig.set_size_inches(6, 8)\n",
        "for j in range(4):\n",
        "  pdf1 = np.histogram(VT[j,:80], bins=xbin_edges)[0]\n",
        "  pdf2 = np.histogram(VT[j,80:], bins=xbin_edges)[0]\n",
        "  axs[j,0].plot(xbin, pdf1, label = \"dogs\")\n",
        "  axs[j,0].plot(xbin, pdf2, label = \"cats\")\n",
        "  axs[j,0].legend()\n",
        "  axs[j,0].set_ylabel('PCA'+str(j+1), fontsize = 18)\n",
        "\n",
        "  pdf1 = np.histogram(VTw[j,:80], bins=xbin_edges)[0]\n",
        "  pdf2 = np.histogram(VTw[j,80:], bins=xbin_edges)[0]\n",
        "  axs[j,1].plot(xbin, pdf1, label = \"dogs\")\n",
        "  axs[j,1].plot(xbin, pdf2, label = \"cats\")\n",
        "  axs[j,1].legend()\n",
        "\n",
        "axs[0,0].set_title(\"image space\", fontsize = 18)\n",
        "axs[0,1].set_title(\"wavelet space\", fontsize = 18)"
      ],
      "metadata": {
        "id": "5WgTvzKdk1Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All dog and cat images projecting to the first three PCA coordinates."
      ],
      "metadata": {
        "id": "EUYjf29Y_vO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(211, projection='3d')\n",
        "ax1.scatter(VT[0,:80],VT[1,:80],VT[2,:80],c='r',marker='o',s=20)\n",
        "ax1.scatter(VT[0,80:],VT[1,80:],VT[2,80:],c='b',marker='o',s=20)\n",
        "\n",
        "ax2 = fig.add_subplot(212, projection='3d')\n",
        "ax2.scatter(VTw[0,:80],VTw[1,:80],VTw[2,:80],c='r',marker='o',s=20)\n",
        "ax2.scatter(VTw[0,80:],VTw[1,80:],VTw[2,80:],c='b',marker='o',s=20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ypSNZWSc93-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Unsupervised Learning: $k$-Means Clustering\n",
        "\n",
        "`scikit-learn` has a built-in function to perform $k$-means clustering.  We will first code our own version of $k$-means to observe how the algorithm behaves for a few iterations, and then learn how to use the `scikit-learn` version.\n",
        "\n",
        "The iteration step for $k$-Means is very straightforward, and the hard part is coming up with a iteration stopping criteria.  We will not explore that part in class but rather use the standard funtions in Python.\n",
        "\n",
        "#### 1. Lloyd's algorithm\n",
        "\n",
        "First, let's prepare a synthetic dataset."
      ],
      "metadata": {
        "id": "NmDgL_tukHO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing set sizes\n",
        "n1 = 100 # Train\n",
        "n2 = 50  # Test\n",
        "\n",
        "# Random ellipse 1 centered at (0,0)\n",
        "x = np.random.randn(n1+n2)\n",
        "y = 0.5*np.random.randn(n1+n2)\n",
        "\n",
        "# Random ellipse 2 centered at (1,-2)\n",
        "x2 = np.random.randn(n1+n2) + 1\n",
        "y2 = 0.2*np.random.randn(n1+n2) - 2\n",
        "\n",
        "# Rotate ellipse 2 by theta\n",
        "theta = np.pi/4\n",
        "A = np.zeros((2,2))\n",
        "A[0,0] = np.cos(theta)\n",
        "A[0,1] = -np.sin(theta)\n",
        "A[1,0] = np.sin(theta)\n",
        "A[1,1] = np.cos(theta)\n",
        "\n",
        "x3 = A[0,0]*x2 + A[0,1]*y2\n",
        "y3 = A[1,0]*x2 + A[1,1]*y2"
      ],
      "metadata": {
        "id": "iJFS6Te7kBoW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(x, y, 'o')\n",
        "plt.plot(x3, y3, 'o')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gnLtn6Kb1_yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write our $k$-means iterations. We will apply the iteration 4 times."
      ],
      "metadata": {
        "id": "Bt-Qv7Rg2MG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will apply k-means to all datas\n",
        "X1 = np.column_stack((x3, y3))\n",
        "X2 = np.column_stack((x, y))\n",
        "\n",
        "Y = np.concatenate((X1, X2))\n",
        "\n",
        "g1 = np.array([-1, 0]) # Initial guess\n",
        "g2 = np.array([1, 0])\n",
        "fig, axs = plt.subplots(2,2)\n",
        "axs = axs.reshape(-1)\n",
        "for j in range(4):\n",
        "  d1 = np.linalg.norm(Y - g1, ord = 2, axis = 1)\n",
        "  d2 = np.linalg.norm(Y - g2, ord = 2, axis = 1)\n",
        "  idx1 = np.where(d1 < d2)\n",
        "  idx2 = np.where(d1 >= d2)\n",
        "  class1 = Y[idx1[0],:]\n",
        "  class2 = Y[idx2[0],:]\n",
        "\n",
        "  axs[j].plot(class1[:,0], class1[:,1], 'o', ms=5)\n",
        "  axs[j].plot(class2[:,0], class2[:,1], 'o', ms=5)\n",
        "  axs[j].plot(g1[0], g1[1], 'k*', ms=10)\n",
        "  axs[j].plot(g2[0], g2[1], 'k*', ms=10)\n",
        "\n",
        "  g1 = np.array([np.mean(class1[:,0]), np.mean(class1[:,1])])\n",
        "  g2 = np.array([np.mean(class2[:,0]), np.mean(class2[:,1])])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2TNfmcXA2EA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use `scikit-learn` to do $k$-means\n",
        "documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
      ],
      "metadata": {
        "id": "O5oANLW5noxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(Y)\n",
        "c = kmeans.cluster_centers_\n",
        "ind = kmeans.labels_"
      ],
      "metadata": {
        "id": "0XaVSvTalH9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx1 = np.where(ind == 0)\n",
        "idx2 = np.where(ind == 1)\n",
        "\n",
        "print(Y.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Y[idx1[0], 0], Y[idx1[0], 1], 'o')\n",
        "plt.plot(Y[idx2[0], 0], Y[idx2[0], 1], 'o')\n",
        "plt.plot(c[:,0], c[:,1], 'k*', ms=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1LQDbyzilhR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}