{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 5: Matrix Norms, SVD, Compression Errors"
      ],
      "metadata": {
        "id": "PK_atcshIU09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuBPWFeRIOjv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.rcParams['xtick.labelsize']=20      # change the tick label size for x axis\n",
        "plt.rcParams['ytick.labelsize']=20      # change the tick label size for x axis\n",
        "plt.rcParams['axes.linewidth']=1        # change the line width of the axis\n",
        "plt.rcParams['xtick.major.width'] = 3   # change the tick line width of x axis\n",
        "plt.rcParams['ytick.major.width'] = 3   # change the tick line width of y axis\n",
        "rc('text', usetex=False)                # disable LaTeX rendering in plots\n",
        "rc('font',**{'family':'DejaVu Sans'})   # set the font of the plot to be DejaVu Sans"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. SVD on dog.jpg\n",
        "\n",
        "Let's first review what we did in Lecture 2 and load the dog.jpg file into Python"
      ],
      "metadata": {
        "id": "79hs-7UdImt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/ME491\"\n",
        "image_path = os.path.join(path, \"image/dog.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGcAqyUSIiJo",
        "outputId": "757edfe8-4c9b-4310-b5e3-62eed378f8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.image import imread\n",
        "\n",
        "A = imread(image_path)"
      ],
      "metadata": {
        "id": "L4JsqxLcRWp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have read in the picture, let's construct matrix X for SVD by converting the image to grayscale."
      ],
      "metadata": {
        "id": "s-d7n_AGRQVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.mean(A, -1) # Convert RGB to grayscale\n",
        "plt.imshow(X, cmap=\"Greys_r\")\n",
        "plt.axis('off') # We don't need axis here so let's remove them"
      ],
      "metadata": {
        "id": "_woP6mneRE6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the equation for SVD, we have\n",
        "$$ X = U\\Sigma V^*$$.\n",
        "\n",
        "Let's now use the numpy build-in SVD function to find $U, \\Sigma$ and $V^*$.\n",
        "Documentation: https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html\n",
        "\n",
        "Recall in lecture 3 we talked about full SVD and economy SVD, `numpy.linalg.svd` can do both, let's look at the results from both of them."
      ],
      "metadata": {
        "id": "eIZGHnBiSAus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the Full SVD\n",
        "U_full, S_full, VT_full =\n",
        "# Take the economy SVD\n",
        "U_econ, S_econ, VT_econ =\n",
        "# Let's look the shape of all matrices\n",
        "print(\"Dimensions of U, S, VT for Full SVD are: \\n\",\n",
        "      np.shape(U_full), np.shape(S_full), np.shape(VT_full))\n",
        "print(\"Dimensions of U, S, VT for Economy SVD are: \\n\",\n",
        "      np.shape(U_econ), np.shape(S_econ), np.shape(VT_econ))"
      ],
      "metadata": {
        "id": "lGsvAqTqRwYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do they both return X?"
      ],
      "metadata": {
        "id": "yXGg0VEcUtwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For full SVD, we need to generate a matrix of nxm\n",
        "# to do the matrix product\n",
        "S_full_mat = np.zeros(X.shape)\n",
        "np.fill_diagonal(S_full_mat, S_full)\n",
        "X_full = U_full @ S_full_mat @ VT_full\n",
        "X_econ = U_econ @ np.diag(S_econ) @ VT_econ"
      ],
      "metadata": {
        "id": "f0XNfRk4SwF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Full SVD returns X: \", np.array_equal(X_full, X))\n",
        "print(\"Economy SVD returns X: \", np.array_equal(X_econ, X))\n",
        "print(\"Full and economy SVD returns the same: \", np.array_equal(X_full, X_econ))\n",
        "print(\"Full SVD returns X: \", np.allclose(X_full, X, atol=1e-8))\n",
        "print(\"Economy SVD returns X: \", np.allclose(X_econ, X, atol=1e-8))\n",
        "print(\"Full and economy SVD returns the same: \", np.allclose(X_full, X_econ, atol=1e-15))"
      ],
      "metadata": {
        "id": "EKKtdkRRSy5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Let's compress dog.jpg\n",
        "\n",
        "First, let's find the rank of $X$.  We know it at most has a rank of 1500, but let's check if all singular values are non-zero.\n",
        "\n",
        "From now on, we will use the results we got from Economy SVD."
      ],
      "metadata": {
        "id": "cIHisrNZXZFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's assign new names so we can type less\n",
        "U, S, VT = U_econ, S_econ, VT_econ\n",
        "\n",
        "# we can use np.where to find the indices for certain conditions\n",
        "idx =\n",
        "print(len(idx[0]))"
      ],
      "metadata": {
        "id": "j4nqkwfbW99L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no zero singular values, so $\\text{rank}(S)=1500$. Any rank $r$ matrix for $r<1500$ will be an approximation of $X$.\n",
        "\n",
        "Let's now apply approximation for the following $r$:\n",
        "$$ r = [1, 5, 20, 100, 100] $$"
      ],
      "metadata": {
        "id": "9VGM_k2sZWrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make 5 subplots in a row\n",
        "fig, axs = plt.subplots(1, 5)\n",
        "j = 0\n",
        "S_diag = np.diag(S)\n",
        "for r in (1000, 100, 20, 5, 1):\n",
        "    # Construct approximate image\n",
        "    # approximate image with first r SVD modes\n",
        "    # U_approx: nxr\n",
        "    # S_approx: rxr\n",
        "    # VT_approx: rxm\n",
        "    Xapprox =\n",
        "    img = axs[j].imshow(Xapprox, cmap='Greys_r')\n",
        "    axs[j].axis('off')\n",
        "    axs[j].set_title('r = ' + str(r))\n",
        "    j += 1"
      ],
      "metadata": {
        "id": "05v6ZlmkY51l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Error Calculations\n",
        "\n",
        "In lecture 3, we learned that the error of the SVD approximation is given by the Frobenius norm.  Because of the properties of the matrices generated by SVD, the error can be simplied to\n",
        "$$||X-\\tilde{X}||_F^2 = \\sum_{k=r+1}^m\\sigma_k^2 $$\n",
        "\n",
        "In this part, let's use `numpy` to find the Frobenius norm of a matrix, and then compare the results with the summation.\n",
        "\n",
        "Note: `numpy.linalg.norm` provides many options to compute different kinds of norms and the default `norm` is the Frobenius norm. For more info, check out the documentation page: https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html"
      ],
      "metadata": {
        "id": "-o72BwombUxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S_sq = S**2\n",
        "S_sq_sum = np.sum(S_sq)\n",
        "for r in (1000, 100, 20, 5, 1):\n",
        "    Xapprox = U[:,:r] @ S_diag[:r,:r] @ VT[:r,:]\n",
        "    X_diff = X - Xapprox\n",
        "    F_norm_sq =\n",
        "    print(\"The Frobenius norm is: \", F_norm_sq)\n",
        "    print(\"The sum of remaining singular values is: \", )"
      ],
      "metadata": {
        "id": "pxGBELbqaDkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You probably noticed that all these numbers are quite big, so let's now find the relative error."
      ],
      "metadata": {
        "id": "Grkl39GJ0nk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm_sq = np.linalg.norm(X)**2\n",
        "for r in (1000, 100, 20, 5, 1):\n",
        "    Xapprox = U[:,:r] @ S_diag[:r,:r] @ VT[:r,:]\n",
        "    X_diff = X - Xapprox\n",
        "    F_norm_sq =\n",
        "    print(\"The relative error from direct norm computation is: \",  \"{:%}\".format())\n",
        "    print(\"The relative error from summing singular values is: \",  \"{:%}\".format())"
      ],
      "metadata": {
        "id": "0xJTFx530shP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Determine rank $r$ given an error estimation\n",
        "\n",
        "Many times, we want to approximate the matrix to a specific value, let's see we want to keep the error to be below $10\\%$, and then compute what rank $r$ we would need.\n",
        "\n",
        "Now let's use `numpy.cumsum` and `numpy.where` to find the $r$ value necessary.\n",
        "\n"
      ],
      "metadata": {
        "id": "QCARjqQEAyYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's find the r necessary for error 0.01, 0.02, 0.05, and 0.1\n",
        "S_sq_cumsum = np.cumsum(S_sq)\n",
        "for error in [0.01, 0.02, 0.05, 0.1]:\n",
        "  all_accuracy =\n",
        "  idx =\n",
        "  r =\n",
        "  print(\"Rank r for error\", error, \"is :\", r)"
      ],
      "metadata": {
        "id": "UFfeOOuJBPhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Connection to Eigenvalue Decomposition\n",
        "\n",
        "We can relate the SVD to an eigenvalue problem by doing the following transformation\n",
        "$$XX^* = U\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}  \\\\\n",
        "    0\n",
        "\\end{bmatrix} V^*V\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}  & 0\n",
        "\\end{bmatrix}U^* = U\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}^2 & 0  \\\\\n",
        "    0 & 0\n",
        "\\end{bmatrix}U^*$$\n",
        "$$X^*X = V\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}  & 0\n",
        "\\end{bmatrix}U^*U\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}  \\\\\n",
        "    0\n",
        "\\end{bmatrix} V^* = V\\hat{\\Sigma}^2V^*$$\n",
        "\n",
        "Recall that $U$ and $V$ are unitary matrices, so $U,\\Sigma,V$ are solutions to the following eigenvalue problems:\n",
        "\n",
        "$$XX^*U=U\\begin{bmatrix}\n",
        "    \\hat{\\Sigma}^2 & 0  \\\\\n",
        "    0 & 0\n",
        "\\end{bmatrix}$$\n",
        "$$X^*XV=V\\hat{\\Sigma}^2$$\n",
        "\n",
        "Now let's test them out"
      ],
      "metadata": {
        "id": "OuVZjBcw7IBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's compute $XX^*$ and $X^*X$"
      ],
      "metadata": {
        "id": "3feOJKHiEABZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to use the build-in function to find X^*, we need to convert\n",
        "# X from an np.ndarray to a matrix\n",
        "X_mat = np.matrix(X)\n",
        "# we convert back to arrays to utilize more generalized functionalities\n",
        "Xh = np.array(X_mat.getH())\n",
        "XXh = np.matmul(X, Xh)\n",
        "XhX = np.matmul(Xh, X)"
      ],
      "metadata": {
        "id": "58gZpKnzxB88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot both products to see how they look"
      ],
      "metadata": {
        "id": "xZzNne_OFJm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make 5 subplots in a row\n",
        "print(\"The shape of XX^* is: \", XXh.shape)\n",
        "print(\"The shape of X^*X is: \", XhX.shape)\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "img = axs[0].imshow(XXh, cmap='Greys_r')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('$XX^*$')\n",
        "img = axs[1].imshow(XhX, cmap='Greys_r')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('$X^*X$')"
      ],
      "metadata": {
        "id": "HLr3U9svxDVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now find the eigenvectors and eigenvalues for both square matrices"
      ],
      "metadata": {
        "id": "8uF3zib7GATv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XXh_value, XXh_vector = np.linalg.eig(XXh)\n",
        "XhX_value, XhX_vector = np.linalg.eig(XhX)"
      ],
      "metadata": {
        "id": "Iyyzi7qfxGZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the eigenvalues to $\\Sigma^2$"
      ],
      "metadata": {
        "id": "FB0Wam0WGVKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogy(np.real(XXh_value), linewidth = 2, label = \"Eigenvalues for $XX^*$\")\n",
        "plt.semilogy(np.real(XhX_value), linewidth = 2, label = \"Eigenvalues for $X^*X$\")\n",
        "plt.semilogy(S_sq, linewidth = 2, label = \"Singular Value Squares\")\n",
        "plt.legend(frameon = False)"
      ],
      "metadata": {
        "id": "EHVo8ewZGUYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. In-class exercise\n",
        "\n",
        "1. generate a matrix of $100\\times50$ with random values of your choosing\n",
        "2. plot the matrix using `imshow`\n",
        "3. perform economy SVD for the matrix\n",
        "4. confirm the rank of the matrix\n",
        "5. choose 3 different ranks and apply matrix approximation\n",
        "6. plot the 3 approximated matrices\n"
      ],
      "metadata": {
        "id": "D42i_nq_H6w8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKRqO0FGJFvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}