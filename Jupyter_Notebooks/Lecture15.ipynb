{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 15: Cross-Validation & Information Criteria"
      ],
      "metadata": {
        "id": "fHksva3a8phf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.rcParams['xtick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['ytick.labelsize']=16      # change the tick label size for x axis\n",
        "plt.rcParams['axes.linewidth']=1        # change the line width of the axis\n",
        "plt.rcParams['xtick.major.width'] = 3   # change the tick line width of x axis\n",
        "plt.rcParams['ytick.major.width'] = 3   # change the tick line width of y axis\n",
        "rc('text', usetex=False)                # disable LaTeX rendering in plots\n",
        "rc('font',**{'family':'DejaVu Sans'})   # set the font of the plot to be DejaVu Sans"
      ],
      "metadata": {
        "id": "1viXqYgG-wCC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. $k$-fold Cross-Validation"
      ],
      "metadata": {
        "id": "B_omWQ07P03c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZrmWsh58muY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "n = 10000\n",
        "L = 4\n",
        "x = np.linspace(0, L, n)\n",
        "lam = 0.1\n",
        "mu = 0.0\n",
        "sigma = 0.1\n",
        "f = x**2 + np.random.normal(mu, sigma, *x.shape)\n",
        "\n",
        "M = 20 # Polynomial degree\n",
        "\n",
        "trials = np.array([2, 10, 100])\n",
        "\n",
        "fig, axs = plt.subplots(3,3)\n",
        "fig.set_size_inches(9, 9)\n",
        "\n",
        "E1 = np.zeros(len(trials))\n",
        "E2 = np.zeros(len(trials))\n",
        "E3 = np.zeros(len(trials))\n",
        "\n",
        "for j in range(len(trials)):\n",
        "  trial = trials[j]\n",
        "\n",
        "  X1 = np.zeros((M, trial))\n",
        "  X2 = np.zeros((M, trial))\n",
        "  X3 = np.zeros((M, trial))\n",
        "\n",
        "  # idx_test = np.random.choice(n, int(n*0.1), replace = False)\n",
        "  idx_test_start = np.random.randint(low = 0, high = int(n-n*0.1))\n",
        "  # idx_test_start = 0\n",
        "  # f_test = f[idx_test]\n",
        "  # x_test = x[idx_test]\n",
        "  f_test = f[idx_test_start:idx_test_start + int(n*0.1)]\n",
        "  x_test = x[idx_test_start:idx_test_start + int(n*0.1)]\n",
        "\n",
        "  # f_train = np.delete(np.copy(f), idx_test)\n",
        "  # x_train = np.delete(np.copy(x), idx_test)\n",
        "  f_train = np.delete(np.copy(f), range(idx_test_start, idx_test_start + int(n*0.1)))\n",
        "  x_train = np.delete(np.copy(x), range(idx_test_start, idx_test_start + int(n*0.1)))\n",
        "\n",
        "  idx_train_all = np.random.choice(len(f_train), (trial, int((n-n*0.1)/trial)), replace = False)\n",
        "\n",
        "  jj = 0\n",
        "  for idx_train in idx_train_all:\n",
        "    A = np.zeros((len(idx_train), M))\n",
        "    for k in range(M):\n",
        "      A[:,k] = x_train[idx_train]**k # build matrix A\n",
        "    A_inv = np.linalg.pinv(np.copy(A))\n",
        "\n",
        "    x1 = A_inv @ np.copy(f_train[idx_train])\n",
        "    f1 = A @ x1\n",
        "\n",
        "    x2 = np.linalg.lstsq(np.copy(A), f_train[idx_train], rcond=None)[0]\n",
        "    f2 = A @ x2\n",
        "\n",
        "    regr3 = linear_model.Lasso(alpha = lam*2)\n",
        "    regr3.fit(A, f_train[idx_train])\n",
        "    x3 = regr3.coef_\n",
        "    f3 = A @ x3\n",
        "\n",
        "    X1[:,jj] = x1\n",
        "    X2[:,jj] = x2\n",
        "    X3[:,jj] = x3\n",
        "\n",
        "    jj += 1\n",
        "\n",
        "  X1m = np.mean(X1, axis=1)\n",
        "  X2m = np.mean(X2, axis=1)\n",
        "  X3m = np.mean(X3, axis=1)\n",
        "\n",
        "  A = np.zeros((len(idx_test), M))\n",
        "  for k in range(M):\n",
        "    A[:,k] = x_test**k # build matrix A\n",
        "  f_valid_1 = A @ X1m\n",
        "  f_valid_2 = A @ X2m\n",
        "  f_valid_3 = A @ X3m\n",
        "\n",
        "  E1[j] = np.linalg.norm(f_valid_1-f_test, ord=2)/np.linalg.norm(f_test, ord=2)\n",
        "  E2[j] = np.linalg.norm(f_valid_2-f_test, ord=2)/np.linalg.norm(f_test, ord=2)\n",
        "  E3[j] = np.linalg.norm(f_valid_3-f_test, ord=2)/np.linalg.norm(f_test, ord=2)\n",
        "\n",
        "  if j == 0:\n",
        "    axs[0,j].set_ylabel(\"pinv\", fontsize = 18)\n",
        "    axs[1,j].set_ylabel(\"backslash\", fontsize = 18)\n",
        "    axs[2,j].set_ylabel(\"LASSO\", fontsize = 18)\n",
        "\n",
        "  axs[0,j].bar(range(M), X1m)\n",
        "  axs[0,j].set_title(\"k=\"+str(trial), fontsize = 18)\n",
        "  axs[1,j].bar(range(M), X2m)\n",
        "  axs[2,j].bar(range(M), X3m)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Error for different $k$ of three different methods"
      ],
      "metadata": {
        "id": "n0NBmrOMP5jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_label = np.arange(3)  # the label locations\n",
        "width = 0.25  # the width of the bars\n",
        "multiplier = 0\n",
        "methods = ['pinv', 'backslash', 'LASSO']\n",
        "E = np.array([E1, E2, E3])\n",
        "E = E.T\n",
        "k = ['k=2', 'k=10', 'k=100']\n",
        "\n",
        "fig, ax = plt.subplots(layout='constrained')\n",
        "\n",
        "for error, kk in zip(E, k):\n",
        "  offset = width * multiplier\n",
        "  rects = ax.bar(x_label + offset, error, width, label=kk)\n",
        "  multiplier += 1\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Error')\n",
        "ax.set_xticks(x_label + width, methods)\n",
        "ax.legend(loc='upper left', ncols=1, fontsize = 18)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XXq--WneBy6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of Training Data and Testing Data"
      ],
      "metadata": {
        "id": "dzGmhYzKVMlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (10, 5), dpi = 80)\n",
        "plt.plot(x_train, f_train, 'o', linewidth=2, label = \"Training Data\")\n",
        "plt.plot(x_test, f_test, 'o', linewidth=2, label = \"Testing Data\")\n",
        "plt.legend(frameon = False, fontsize = 18)\n",
        "plt.xlabel('$x$', fontsize = 18)\n",
        "plt.ylabel('$f(x)$', fontsize = 18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GTXND-MIFMME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Information Criteria\n",
        "\n",
        "The Kullback-Leibler (KL) divergence measures the distance between two probability density distributions (or data sets which represent the truth and a model) and is the core of modern information theory criteria for evaluating the viability of a model.\n",
        "\n",
        "The KL divergence between two models $f(\\mathrm{X},\\mathrm{\\beta})$ and $g(\\mathrm{X},\\mathrm{\\mu})$ is defined as:\n",
        "\n",
        "$$ I(f, g) = \\int f(\\mathrm{X},\\mathrm{\\beta})\\log\\left[\\frac{f(\\mathrm{X},\\mathrm{\\beta})}{g(\\mathrm{X},\\mathrm{\\mu})}\\right]d\\mathrm{X} $$\n",
        "\n",
        "$\\mathrm{\\beta}$: parameterizations of model $f$.\n",
        "\n",
        "$\\mathrm{\\mu}$: parameterizations of model $g$.\n",
        "\n",
        "From an information theory perspective, the quantity $I(f,g)$ measures the information lost when $g$ is used to represent $f$. Note that if $f = g$, then the log term is zero (i.e., $\\log(1) = 0$) and $I(f, g) = 0$, so that there is no information lost.\n",
        "\n",
        "In practice, $f$ will represent the \\emph{truth}, or measurements of an experiment, while $g$ will be a model proposed to describe $f$."
      ],
      "metadata": {
        "id": "HYy_0x2vVSUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Textbook example (Fig. 4.21)"
      ],
      "metadata": {
        "id": "q6iu_YSQkSQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "x1 = np.random.randn(n) # \"truth\" model (data)\n",
        "x2 = 0.8 * np.random.randn(n) + 1 # model 1\n",
        "x3 = 0.5 * np.random.randn(n) - 1 # model 3 components\n",
        "x4 = 0.7 * np.random.randn(n) - 3\n",
        "x5 = 5.0 * np.random.rand(n) - 0.5\n",
        "\n",
        "x = np.arange(-6,6.01,0.01) # range for data\n",
        "x_bincenters = np.arange(-6.005,6.01,0.01)"
      ],
      "metadata": {
        "id": "SLzNgpIBjsra"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = np.histogram(x1,bins=x_bincenters)[0] + 0.01 # generate PDFs\n",
        "g1 = np.histogram(x2,bins=x_bincenters)[0] + 0.01\n",
        "g2a = np.histogram(x3,bins=x_bincenters)[0]\n",
        "g2b = np.histogram(x4,bins=x_bincenters)[0]\n",
        "g2 = g2a + 0.3*g2b + 0.01\n",
        "g3 = np.histogram(x5,bins=x_bincenters)[0] + 0.01\n",
        "\n",
        "f = f/np.trapz(f,x) # normalize data\n",
        "g1 = g1/np.trapz(g1,x)\n",
        "g2 = g2/np.trapz(g2,x)\n",
        "g3 = g3/np.trapz(g3,x)\n",
        "\n",
        "# Compute integrand\n",
        "Int1 = f * np.log(np.divide(f,g1))\n",
        "Int2 = f * np.log(np.divide(f,g2))\n",
        "Int3 = f * np.log(np.divide(f,g3))\n",
        "\n",
        "# KL divergence\n",
        "I1 = np.trapz(Int1,x)\n",
        "I2 = np.trapz(Int2,x)\n",
        "I3 = np.trapz(Int3,x)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x,f,linewidth=2,label='f')\n",
        "plt.plot(x,g1,linewidth=2,label='g1')\n",
        "plt.plot(x,g2,linewidth=2,label='g2')\n",
        "plt.plot(x,g3,linewidth=2,label='g3')\n",
        "plt.text(-6, 0.78, 'I1='+str(round(I1, 3)), fontsize = 15)\n",
        "plt.text(-6, 0.73, 'I2='+str(round(I2, 3)), fontsize = 15)\n",
        "plt.text(-6, 0.68, 'I3='+str(round(I3, 3)), fontsize = 15)\n",
        "plt.legend(fontsize = 18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zJ1GuYTnH0j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Apply KL Divergence Calculation for $f(x) = x^2$ fitting"
      ],
      "metadata": {
        "id": "BVmOKmXVloFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Int_pinv = f_test * np.log(np.abs((f_test/f_valid_1)))\n",
        "Int_back = f_test * np.log(np.abs((f_test/f_valid_2)))\n",
        "Int_lasso = f_test * np.log(np.abs((f_test/f_valid_3)))\n",
        "\n",
        "I_pinv = np.trapz(Int_pinv, x_test)\n",
        "I_back = np.trapz(Int_back, x_test)\n",
        "I_lasso = np.trapz(Int_lasso, x_test)\n",
        "\n",
        "print(\"KL Divergence for pinv is: \", I_pinv)\n",
        "print(\"KL Divergence for backslash is: \", I_back)\n",
        "print(\"KL Divergence for LASSO is: \", I_lasso)"
      ],
      "metadata": {
        "id": "KTI4ENrvl8t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "prU4Jr9JnOcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}